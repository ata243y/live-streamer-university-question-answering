import json
import os
import sys
import time
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import statistics

# Proje kÃ¶k dizini
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)

try:
    from qa_app.core.rag_engine import RAGEngine

except ImportError:
    print("HATA: 'qa_app.rag_engine' modÃ¼lÃ¼ bulunamadÄ±.")
    sys.exit(1)


@dataclass
class TestCase:
    """Tek bir test sorusunu temsil eder"""
    question: str
    category: str
    difficulty: str  # "easy", "medium", "hard"
    expected_keywords: List[str]  # CevaptazÄ± burada olmasÄ± gereken kelimeler
    should_contain_source: bool = True  # Context'te kaynak belge bekleniyor mu?
    

@dataclass
class TestResult:
    """Bir test sonucunu temsil eder"""
    question: str
    category: str
    difficulty: str
    answer: str
    contexts: List[str]
    response_time: float
    contains_keywords: bool
    has_context: bool
    error: Optional[str] = None
    timestamp: str = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()


# --- GENÄ°ÅLETÄ°LMÄ°Å TEST SETÄ° (100+ SORU) ---
TEST_SUITE = [
    # === Ã‡AP / YANDAL (20 soru) ===
    TestCase("Ã‡ift anadal programÄ±na baÅŸvuru koÅŸullarÄ± nelerdir?", "cap_yandal", "medium",
             ["GANO", "3.0", "baÅŸvuru", "koÅŸul"]),
    TestCase("Ã‡AP yapmak iÃ§in GANO en az kaÃ§ olmalÄ±?", "cap_yandal", "easy",
             ["3.0", "GANO"]),
    TestCase("Yandal baÅŸvurusu nasÄ±l yapÄ±lÄ±r?", "cap_yandal", "medium",
             ["baÅŸvuru", "online", "sistem"]),
    TestCase("Kimler Ã§ift anadal programÄ±na baÅŸvuramaz?", "cap_yandal", "medium",
             ["disiplin", "ceza", "ÅŸart"]),
    TestCase("Ã‡AP programÄ±ndan Ã§Ä±karÄ±lma ÅŸartlarÄ± nelerdir?", "cap_yandal", "medium",
             ["GANO", "dÃ¼ÅŸÃ¼k", "baÅŸarÄ±sÄ±z"]),
    TestCase("Yandal diploma almak iÃ§in kaÃ§ kredi gerekir?", "cap_yandal", "easy",
             ["kredi", "30", "diploma"]),
    TestCase("Ã‡AP'tan mezuniyet iÃ§in ÅŸartlar nelerdir?", "cap_yandal", "hard",
             ["mezuniyet", "GANO", "gerekli"]),
    TestCase("Yandal programÄ±nda kaÃ§ ders almak zorunludur?", "cap_yandal", "medium",
             ["ders", "sayÄ±", "zorunlu"]),
    TestCase("Ã‡AP Ã¶ÄŸrencisi dÃ¶nemde en fazla kaÃ§ AKTS alabilir?", "cap_yandal", "medium",
             ["AKTS", "dÃ¶nem", "maksimum"]),
    TestCase("Yandal programÄ±na hangi dÃ¶nemde baÅŸvurulur?", "cap_yandal", "easy",
             ["dÃ¶nem", "baÅŸvuru", "tarih"]),
    TestCase("Ã‡AP Ã¶ÄŸrencisi ara sÄ±nÄ±fta kalÄ±rsa ne olur?", "cap_yandal", "hard",
             ["ara sÄ±nÄ±f", "durum", "sonuÃ§"]),
    TestCase("Yandal programÄ± kaÃ§ yÄ±lda tamamlanÄ±r?", "cap_yandal", "medium",
             ["yÄ±l", "sÃ¼re", "tamamlama"]),
    TestCase("Ã‡AP Ã¶ÄŸrencisi staj yapmak zorunda mÄ±?", "cap_yandal", "medium",
             ["staj", "zorunlu", "Ã‡AP"]),
    TestCase("Yandal diplomasÄ± ana diploma ile birlikte mi verilir?", "cap_yandal", "easy",
             ["diploma", "teslim", "birlikte"]),
    TestCase("Ã‡AP baÅŸvurusu iÃ§in hangi belgeler gerekir?", "cap_yandal", "medium",
             ["belge", "baÅŸvuru", "gerekli"]),
    TestCase("Yandal programÄ±nda ders seÃ§imi nasÄ±l yapÄ±lÄ±r?", "cap_yandal", "medium",
             ["ders seÃ§imi", "kayÄ±t", "sistem"]),
    TestCase("Ã‡AP Ã¶ÄŸrencisinin danÄ±ÅŸmanÄ± kim olur?", "cap_yandal", "easy",
             ["danÄ±ÅŸman", "kim", "Ã‡AP"]),
    TestCase("Yandal programÄ±nda FF aldÄ±ÄŸÄ±mda ne olur?", "cap_yandal", "hard",
             ["FF", "baÅŸarÄ±sÄ±zlÄ±k", "sonuÃ§"]),
    TestCase("Ã‡AP ile yandal arasÄ±ndaki fark nedir?", "cap_yandal", "medium",
             ["fark", "Ã‡AP", "yandal"]),
    TestCase("Yandal Ã¶ÄŸrencisi mezuniyet projesine katÄ±lÄ±r mÄ±?", "cap_yandal", "hard",
             ["mezuniyet projesi", "katÄ±lÄ±m", "yandal"]),
    
    # === YATAY GEÃ‡Ä°Å (15 soru) ===
    TestCase("Kurumlar arasÄ± yatay geÃ§iÅŸ iÃ§in YKS puanÄ± ne kadar etkili?", "yatay_gecis", "medium",
             ["YKS", "puan", "%50"]),
    TestCase("Yatay geÃ§iÅŸ baÅŸvurularÄ± ne zaman yapÄ±lÄ±r?", "yatay_gecis", "easy",
             ["baÅŸvuru", "tarih", "dÃ¶nem"]),
    TestCase("AGNO ile yatay geÃ§iÅŸ ÅŸartlarÄ± nelerdir?", "yatay_gecis", "medium",
             ["AGNO", "ÅŸart", "geÃ§iÅŸ"]),
    TestCase("HazÄ±rlÄ±k okuyan Ã¶ÄŸrenci yatay geÃ§iÅŸ yapabilir mi?", "yatay_gecis", "medium",
             ["hazÄ±rlÄ±k", "yatay geÃ§iÅŸ", "ÅŸart"]),
    TestCase("Yatay geÃ§iÅŸte kontenjan nasÄ±l belirlenir?", "yatay_gecis", "hard",
             ["kontenjan", "belirleme", "kriter"]),
    TestCase("DGS ile yatay geÃ§iÅŸ yapÄ±labilir mi?", "yatay_gecis", "medium",
             ["DGS", "geÃ§iÅŸ", "mÃ¼mkÃ¼n"]),
    TestCase("Yatay geÃ§iÅŸte hangi dersler muaf tutuluÄ±r?", "yatay_gecis", "hard",
             ["ders muafiyeti", "intibak", "kabul"]),
    TestCase("Kurumlar arasÄ± yatay geÃ§iÅŸ iÃ§in minimum AGNO kaÃ§ olmalÄ±?", "yatay_gecis", "easy",
             ["AGNO", "minimum", "ÅŸart"]),
    TestCase("Yatay geÃ§iÅŸ baÅŸvurusu hangi belgeleri iÃ§erir?", "yatay_gecis", "medium",
             ["belge", "baÅŸvuru", "gerekli"]),
    TestCase("Yatay geÃ§iÅŸte ek kontenjan var mÄ±?", "yatay_gecis", "medium",
             ["ek kontenjan", "var", "yok"]),
    TestCase("Yatay geÃ§iÅŸ sonuÃ§larÄ± ne zaman aÃ§Ä±klanÄ±r?", "yatay_gecis", "easy",
             ["sonuÃ§", "aÃ§Ä±klama", "tarih"]),
    TestCase("Ä°Ã§ yatay geÃ§iÅŸ ile dÄ±ÅŸ yatay geÃ§iÅŸ arasÄ±ndaki fark nedir?", "yatay_gecis", "medium",
             ["iÃ§", "dÄ±ÅŸ", "fark"]),
    TestCase("Yatay geÃ§iÅŸte Ã¼st sÄ±nÄ±fa geÃ§iÅŸ koÅŸulu var mÄ±?", "yatay_gecis", "hard",
             ["Ã¼st sÄ±nÄ±f", "koÅŸul", "ÅŸart"]),
    TestCase("Yatay geÃ§iÅŸ yapan Ã¶ÄŸrenci hangi sÄ±nÄ±fa yerleÅŸir?", "yatay_gecis", "medium",
             ["sÄ±nÄ±f", "yerleÅŸtirme", "belirleme"]),
    TestCase("Yatay geÃ§iÅŸ baÅŸvurusu reddedilirse itiraz edilebilir mi?", "yatay_gecis", "medium",
             ["red", "itiraz", "baÅŸvuru"]),
    
    # === LÄ°SANSÃœSTÃœ (20 soru) ===
    TestCase("LisansÃ¼stÃ¼ eÄŸitim yÃ¶netmeliÄŸine gÃ¶re bir dersten baÅŸarÄ±lÄ± sayÄ±lma notu nedir?", "lisansustu", "easy",
             ["CB", "2.5", "baÅŸarÄ±"]),
    TestCase("Tez savunmasÄ±na girmek iÃ§in ÅŸartlar nelerdir?", "lisansustu", "hard",
             ["tez savunma", "ÅŸart", "koÅŸul"]),
    TestCase("YÃ¼ksek lisans tez sÃ¼resi kaÃ§ yÄ±ldÄ±r?", "lisansustu", "easy",
             ["yÃ¼ksek lisans", "2 yÄ±l", "sÃ¼re"]),
    TestCase("Doktora programÄ±na kimler baÅŸvurabilir?", "lisansustu", "medium",
             ["doktora", "baÅŸvuru", "ÅŸart"]),
    TestCase("LisansÃ¼stÃ¼ Ã¶ÄŸrenci kayÄ±t dondurabilir mi?", "lisansustu", "medium",
             ["kayÄ±t dondurma", "izin", "sÃ¼re"]),
    TestCase("YÃ¼ksek lisans tez jÃ¼risinde kaÃ§ kiÅŸi olur?", "lisansustu", "easy",
             ["jÃ¼ri", "3", "5"]),
    TestCase("Doktora yeterlik sÄ±navÄ± kaÃ§ defa yapÄ±labilir?", "lisansustu", "medium",
             ["yeterlik", "sÄ±nav", "hak"]),
    TestCase("LisansÃ¼stÃ¼ Ã¶ÄŸrencisi en fazla kaÃ§ AKTS alabilir?", "lisansustu", "medium",
             ["AKTS", "maksimum", "dÃ¶nem"]),
    TestCase("Tez yazÄ±m kurallarÄ± nerede belirtiliyor?", "lisansustu", "medium",
             ["tez yazÄ±m", "kÄ±lavuz", "format"]),
    TestCase("Doktorada dil ÅŸartÄ± nedir?", "lisansustu", "hard",
             ["dil", "ALES", "puan"]),
    TestCase("YÃ¼ksek lisans tez jÃ¼risi nasÄ±l belirlenir?", "lisansustu", "hard",
             ["jÃ¼ri", "seÃ§im", "onay"]),
    TestCase("LisansÃ¼stÃ¼ Ã¶ÄŸrenci yurt dÄ±ÅŸÄ±na Ã§Ä±kabilir mi?", "lisansustu", "medium",
             ["yurt dÄ±ÅŸÄ±", "izin", "sÃ¼re"]),
    TestCase("Doktora tez Ã¶nerisi ne zaman sunulur?", "lisansustu", "medium",
             ["tez Ã¶nerisi", "tarih", "dÃ¶nem"]),
    TestCase("LisansÃ¼stÃ¼ burs baÅŸvurusu nasÄ±l yapÄ±lÄ±r?", "lisansustu", "medium",
             ["burs", "baÅŸvuru", "ÅŸart"]),
    TestCase("YÃ¼ksek lisans tezsiz programda kaÃ§ kredi alÄ±nÄ±r?", "lisansustu", "easy",
             ["tezsiz", "kredi", "30"]),
    TestCase("Doktora Ã¶ÄŸrencisi ders gÃ¶revlisi olabilir mi?", "lisansustu", "medium",
             ["ders gÃ¶revlisi", "Ã§alÄ±ÅŸma", "izin"]),
    TestCase("LisansÃ¼stÃ¼ mezuniyet iÃ§in GANO ÅŸartÄ± var mÄ±?", "lisansustu", "medium",
             ["GANO", "mezuniyet", "ÅŸart"]),
    TestCase("Tez danÄ±ÅŸmanÄ± nasÄ±l deÄŸiÅŸtirilir?", "lisansustu", "hard",
             ["danÄ±ÅŸman", "deÄŸiÅŸtirme", "prosedÃ¼r"]),
    TestCase("Doktorada yayÄ±n ÅŸartÄ± nedir?", "lisansustu", "hard",
             ["yayÄ±n", "makale", "ÅŸart"]),
    TestCase("LisansÃ¼stÃ¼ program deÄŸiÅŸikliÄŸi yapÄ±labilir mi?", "lisansustu", "medium",
             ["program deÄŸiÅŸikliÄŸi", "geÃ§iÅŸ", "ÅŸart"]),
    
    # === STAJ (12 soru) ===
    TestCase("Ä°ÅŸletme fakÃ¼ltesi staj yÃ¶nergesine gÃ¶re staj sÃ¼resi kaÃ§ gÃ¼ndÃ¼r?", "staj", "easy",
             ["30 gÃ¼n", "sÃ¼re", "iÅŸ gÃ¼nÃ¼"]),
    TestCase("Staj raporu ne zaman teslim edilmeli?", "staj", "medium",
             ["rapor", "teslim", "tarih"]),
    TestCase("Staj yapabileceÄŸim yerler nasÄ±l onaylanÄ±r?", "staj", "medium",
             ["onay", "kurum", "SGK"]),
    TestCase("Zorunlu staj hangi dÃ¶nemde yapÄ±lÄ±r?", "staj", "easy",
             ["dÃ¶nem", "yaz", "staj"]),
    TestCase("Staj defteri nasÄ±l doldurulur?", "staj", "medium",
             ["defter", "form", "doldurma"]),
    TestCase("Yurt dÄ±ÅŸÄ±nda staj yapÄ±labilir mi?", "staj", "medium",
             ["yurt dÄ±ÅŸÄ±", "staj", "onay"]),
    TestCase("Staj komisyonu kimlerden oluÅŸur?", "staj", "medium",
             ["komisyon", "Ã¼ye", "Ã¶ÄŸretim"]),
    TestCase("Staj deÄŸerlendirmesi nasÄ±l yapÄ±lÄ±r?", "staj", "hard",
             ["deÄŸerlendirme", "not", "baÅŸarÄ±"]),
    TestCase("Staj sigorta iÅŸlemleri kim tarafÄ±ndan yapÄ±lÄ±r?", "staj", "medium",
             ["sigorta", "SGK", "iÅŸlemler"]),
    TestCase("Staj baÅŸvurusu hangi belgeleri iÃ§erir?", "staj", "medium",
             ["baÅŸvuru", "belge", "gerekli"]),
    TestCase("Kendi ÅŸirketimde staj yapabilir miyim?", "staj", "hard",
             ["kendi ÅŸirket", "akraba", "onay"]),
    TestCase("Staj yapmazsam ne olur?", "staj", "easy",
             ["zorunlu", "mezuniyet", "engel"]),
    
    # === EÄÄ°TÄ°M YÃ–NETMELÄ°ÄÄ° (15 soru) ===
    TestCase("Ä°ngilizce hazÄ±rlÄ±k programÄ±ndan muafiyet koÅŸullarÄ± nelerdir?", "egitim", "medium",
             ["muafiyet", "TÃ–MER", "puan"]),
    TestCase("Bir dÃ¶nemde en fazla kaÃ§ AKTS alabilirim?", "egitim", "easy",
             ["AKTS", "maksimum", "45"]),
    TestCase("FF notu GANO'ya nasÄ±l etki eder?", "egitim", "medium",
             ["FF", "GANO", "hesap"]),
    TestCase("Ders kaydÄ±nÄ± ne zamana kadar iptal edebilirim?", "egitim", "medium",
             ["ders kaydÄ±", "iptal", "tarih"]),
    TestCase("Ara sÄ±nÄ±fta kalma ÅŸartlarÄ± nelerdir?", "egitim", "hard",
             ["ara sÄ±nÄ±f", "ÅŸart", "AKTS"]),
    TestCase("Mazeret sÄ±navÄ±na kimler girebilir?", "egitim", "medium",
             ["mazeret", "sÄ±nav", "ÅŸart"]),
    TestCase("Ders tekrarÄ± nasÄ±l yapÄ±lÄ±r?", "egitim", "medium",
             ["tekrar", "ders", "kayÄ±t"]),
    TestCase("DevamsÄ±zlÄ±k sÄ±nÄ±rÄ± nedir?", "egitim", "easy",
             ["devamsÄ±zlÄ±k", "%30", "sÄ±nÄ±r"]),
    TestCase("BÃ¼tÃ¼nleme sÄ±navÄ±na kimler girer?", "egitim", "medium",
             ["bÃ¼tÃ¼nleme", "ÅŸart", "baÅŸarÄ±sÄ±z"]),
    TestCase("Ders programÄ± deÄŸiÅŸikliÄŸi ne zaman yapÄ±labilir?", "egitim", "medium",
             ["ders programÄ±", "deÄŸiÅŸiklik", "tarih"]),
    TestCase("Ã–ÄŸrenci disiplin cezalarÄ± nelerdir?", "egitim", "hard",
             ["disiplin", "ceza", "tÃ¼rÃ¼"]),
    TestCase("KayÄ±t dondurmak iÃ§in ÅŸartlar nelerdir?", "egitim", "medium",
             ["kayÄ±t dondurma", "ÅŸart", "sÃ¼re"]),
    TestCase("Ã‡ift kayÄ±t yapÄ±labilir mi?", "egitim", "easy",
             ["Ã§ift kayÄ±t", "yasak", "mÃ¼mkÃ¼n"]),
    TestCase("Ã–zel Ã¶ÄŸrenci statÃ¼sÃ¼ nedir?", "egitim", "hard",
             ["Ã¶zel Ã¶ÄŸrenci", "tanÄ±m", "ÅŸart"]),
    TestCase("Mezuniyet iÃ§in gereken toplam AKTS kaÃ§tÄ±r?", "egitim", "easy",
             ["mezuniyet", "AKTS", "240"]),
    
    # === FÄ°KRÄ° MÃœLKÄ°YET & TTO (10 soru) ===
    TestCase("Teknoloji Transfer Ofisi'nin gÃ¶revleri nelerdir?", "fikri_mulkiyet", "medium",
             ["TTO", "gÃ¶rev", "buluÅŸ"]),
    TestCase("Fikri ve SÄ±nai MÃ¼lkiyet HaklarÄ± yÃ¶nergesine gÃ¶re buluÅŸ bildirimi nasÄ±l yapÄ±lÄ±r?", "fikri_mulkiyet", "hard",
             ["buluÅŸ", "bildirim", "form"]),
    TestCase("Patent baÅŸvurusu kime aittir?", "fikri_mulkiyet", "medium",
             ["patent", "sahiplik", "Ã¼niversite"]),
    TestCase("BuluÅŸtan elde edilen gelir nasÄ±l paylaÅŸÄ±lÄ±r?", "fikri_mulkiyet", "hard",
             ["gelir", "paylaÅŸÄ±m", "yÃ¼zde"]),
    TestCase("AraÅŸtÄ±rmacÄ± buluÅŸ bildirimi yapmak zorunda mÄ±?", "fikri_mulkiyet", "medium",
             ["zorunluluk", "bildirim", "buluÅŸ"]),
    TestCase("TTO hangi birimlere hizmet verir?", "fikri_mulkiyet", "medium",
             ["TTO", "hizmet", "araÅŸtÄ±rmacÄ±"]),
    TestCase("Patent masraflarÄ± kim tarafÄ±ndan karÅŸÄ±lanÄ±r?", "fikri_mulkiyet", "medium",
             ["masraf", "patent", "Ã¶deme"]),
    TestCase("Ticari sÄ±r kapsamÄ±na neler girer?", "fikri_mulkiyet", "hard",
             ["ticari sÄ±r", "tanÄ±m", "kapsam"]),
    TestCase("Lisans anlaÅŸmasÄ± nedir?", "fikri_mulkiyet", "medium",
             ["lisans", "anlaÅŸma", "patent"]),
    TestCase("Spin-off ÅŸirket kurulabilir mi?", "fikri_mulkiyet", "hard",
             ["spin-off", "ÅŸirket", "izin"]),
    
    # === KISMI ZAMANLI Ã‡ALIÅMA (8 soru) ===
    TestCase("KÄ±smi zamanlÄ± Ã¶ÄŸrenci Ã§alÄ±ÅŸtÄ±rma programÄ±na kimler baÅŸvurabilir?", "kismi_zamanli", "medium",
             ["baÅŸvuru", "ÅŸart", "Ã¶ÄŸrenci"]),
    TestCase("KÄ±smi zamanlÄ± Ã§alÄ±ÅŸmada haftalÄ±k Ã§alÄ±ÅŸma sÃ¼resi kaÃ§ saattir?", "kismi_zamanli", "easy",
             ["10 saat", "haftalÄ±k", "sÃ¼re"]),
    TestCase("KÄ±smi zamanlÄ± Ã§alÄ±ÅŸan Ã¶ÄŸrenciye Ã¼cret Ã¶denir mi?", "kismi_zamanli", "easy",
             ["Ã¼cret", "Ã¶deme", "var"]),
    TestCase("KÄ±smi zamanlÄ± Ã§alÄ±ÅŸma baÅŸvurusu ne zaman yapÄ±lÄ±r?", "kismi_zamanli", "medium",
             ["baÅŸvuru", "tarih", "dÃ¶nem"]),
    TestCase("Hangi birimlerde kÄ±smi zamanlÄ± Ã§alÄ±ÅŸÄ±labilir?", "kismi_zamanli", "medium",
             ["birim", "yer", "kÃ¼tÃ¼phane"]),
    TestCase("KÄ±smi zamanlÄ± Ã§alÄ±ÅŸma sÃ¶zleÅŸmesi kaÃ§ dÃ¶nem geÃ§erlidir?", "kismi_zamanli", "medium",
             ["sÃ¶zleÅŸme", "sÃ¼re", "dÃ¶nem"]),
    TestCase("KÄ±smi zamanlÄ± Ã§alÄ±ÅŸmadan Ã§Ä±karÄ±lma sebepleri nelerdir?", "kismi_zamanli", "hard",
             ["Ã§Ä±karÄ±lma", "sebep", "disiplin"]),
    TestCase("KÄ±smi zamanlÄ± Ã§alÄ±ÅŸan Ã¶ÄŸrencinin GANO ÅŸartÄ± var mÄ±?", "kismi_zamanli", "medium",
             ["GANO", "ÅŸart", "2.0"]),
    
    # === KAPSAM DIÅI / OUT-OF-SCOPE (10 soru) ===
    TestCase("GTÃœ yemekhanesinde bugÃ¼n ne yemek var?", "out_of_scope", "easy",
             [], False),  # Cevap verilememeli
    TestCase("RektÃ¶rÃ¼n adÄ± nedir?", "out_of_scope", "easy",
             [], False),
    TestCase("Merhaba, nasÄ±lsÄ±n?", "out_of_scope", "easy",
             [], False),
    TestCase("BugÃ¼n hava nasÄ±l?", "out_of_scope", "easy",
             [], False),
    TestCase("YakÄ±nlarda iyi bir kafe var mÄ±?", "out_of_scope", "medium",
             [], False),
    TestCase("Python'da liste nasÄ±l oluÅŸturulur?", "out_of_scope", "medium",
             [], False),
    TestCase("En sevdiÄŸin renk hangisi?", "out_of_scope", "easy",
             [], False),
    TestCase("BugÃ¼n hangi dersten sÄ±nav var?", "out_of_scope", "medium",
             [], False),
    TestCase("Kantinde Ã§ay kaÃ§ lira?", "out_of_scope", "easy",
             [], False),
    TestCase("OtobÃ¼s saatleri nedir?", "out_of_scope", "easy",
             [], False),
]


class TestRunner:
    """Test suite'ini Ã§alÄ±ÅŸtÄ±ran ve sonuÃ§larÄ± analiz eden sÄ±nÄ±f"""
    
    def __init__(self, output_dir: str = None):
        self.rag_engine = RAGEngine()
        self.output_dir = output_dir or project_root
        self.results: List[TestResult] = []
        
    def run_single_test(self, test_case: TestCase) -> TestResult:
        """Tek bir test case'ini Ã§alÄ±ÅŸtÄ±rÄ±r"""
        start_time = time.time()
        error = None
        answer = ""
        contexts = []
        
        try:
            response = self.rag_engine.answer_query_with_context(test_case.question)
            answer_gen = response.get("answer", [])
            contexts = response.get("contexts", [])
            
            # Generator'Ä± stringe Ã§evir
            answer = "".join(list(answer_gen))
            
        except Exception as e:
            error = str(e)
            answer = "[HATA]"
            
        response_time = time.time() - start_time
        
        # Keyword kontrolÃ¼
        contains_keywords = self._check_keywords(answer, test_case.expected_keywords)
        has_context = len(contexts) > 0 if test_case.should_contain_source else True
        
        return TestResult(
            question=test_case.question,
            category=test_case.category,
            difficulty=test_case.difficulty,
            answer=answer.strip(),
            contexts=contexts,
            response_time=response_time,
            contains_keywords=contains_keywords,
            has_context=has_context,
            error=error
        )
    
    def _check_keywords(self, answer: str, keywords: List[str]) -> bool:
        """CevabÄ±n Ã¶nemli kelimeleri iÃ§erip iÃ§ermediÄŸini kontrol eder"""
        if not keywords:
            return True
        answer_lower = answer.lower()
        return any(kw.lower() in answer_lower for kw in keywords)
    
    def run_tests(self, max_workers: int = 5):
        """TÃ¼m testleri paralel olarak Ã§alÄ±ÅŸtÄ±rÄ±r"""
        print(f"\n{'='*60}")
        print(f"GTÃœ QA Bot Evaluation Suite")
        print(f"Toplam Test: {len(TEST_SUITE)}")
        print(f"Paralel Worker: {max_workers}")
        print(f"{'='*60}\n")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(self.run_single_test, tc): tc for tc in TEST_SUITE}
            
            for future in tqdm(as_completed(futures), total=len(TEST_SUITE), desc="Testler"):
                result = future.result()
                self.results.append(result)
    
    def calculate_metrics(self) -> Dict:
        """Test sonuÃ§larÄ±ndan metrikler hesaplar"""
        total = len(self.results)
        
        # Kategori bazlÄ± skorlar
        category_scores = {}
        difficulty_scores = {}
        
        for result in self.results:
            # Kategori
            if result.category not in category_scores:
                category_scores[result.category] = {"total": 0, "passed": 0}
            category_scores[result.category]["total"] += 1
            
            # Zorluk
            if result.difficulty not in difficulty_scores:
                difficulty_scores[result.difficulty] = {"total": 0, "passed": 0}
            difficulty_scores[result.difficulty]["total"] += 1
            
            # BaÅŸarÄ± kontrolÃ¼ (keywords ve context)
            passed = result.contains_keywords and result.has_context and not result.error
            if passed:
                category_scores[result.category]["passed"] += 1
                difficulty_scores[result.difficulty]["passed"] += 1
        
        # Response time istatistikleri
        response_times = [r.response_time for r in self.results if r.response_time]
        
        # BaÅŸarÄ± oranÄ±
        total_passed = sum(cs["passed"] for cs in category_scores.values())
        overall_success_rate = (total_passed / total * 100) if total > 0 else 0
        
        metrics = {
            "total_tests": total,
            "total_passed": total_passed,
            "overall_success_rate": round(overall_success_rate, 2),
            "avg_response_time": round(statistics.mean(response_times), 3) if response_times else 0,
            "median_response_time": round(statistics.median(response_times), 3) if response_times else 0,
            "max_response_time": round(max(response_times), 3) if response_times else 0,
            "category_scores": {
                cat: {
                    "passed": data["passed"],
                    "total": data["total"],
                    "success_rate": round(data["passed"] / data["total"] * 100, 2)
                }
                for cat, data in category_scores.items()
            },
            "difficulty_scores": {
                diff: {
                    "passed": data["passed"],
                    "total": data["total"],
                    "success_rate": round(data["passed"] / data["total"] * 100, 2)
                }
                for diff, data in difficulty_scores.items()
            },
            "errors": sum(1 for r in self.results if r.error)
        }
        
        return metrics
    
    def save_results(self):
        """SonuÃ§larÄ± ve metrikleri kaydeder"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # DetaylÄ± sonuÃ§lar
        results_file = os.path.join(self.output_dir, f"test_results_{timestamp}.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump([asdict(r) for r in self.results], f, ensure_ascii=False, indent=2)
        
        # Metrikler
        metrics = self.calculate_metrics()
        metrics_file = os.path.join(self.output_dir, f"test_metrics_{timestamp}.json")
        with open(metrics_file, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, ensure_ascii=False, indent=2)
        
        # Ã–zet rapor (okunabilir)
        report_file = os.path.join(self.output_dir, f"test_report_{timestamp}.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(self._generate_report(metrics))
        
        print(f"\n{'='*60}")
        print(f"âœ… Test TamamlandÄ±!")
        print(f"ğŸ“Š SonuÃ§lar: {results_file}")
        print(f"ğŸ“ˆ Metrikler: {metrics_file}")
        print(f"ğŸ“„ Rapor: {report_file}")
        print(f"{'='*60}\n")
        
        # Konsola Ã¶zet yazdÄ±r
        print(self._generate_report(metrics))
    
    def _generate_report(self, metrics: Dict) -> str:
        """Okunabilir metin raporu oluÅŸturur"""
        report = []
        report.append("="*60)
        report.append("GTÃœ QA BOT DEÄERLENDÄ°RME RAPORU")
        report.append("="*60)
        report.append(f"\nTarih: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"\nğŸ“Š GENEL SONUÃ‡LAR:")
        report.append(f"  â€¢ Toplam Test: {metrics['total_tests']}")
        report.append(f"  â€¢ BaÅŸarÄ±lÄ±: {metrics['total_passed']}")
        report.append(f"  â€¢ BaÅŸarÄ± OranÄ±: %{metrics['overall_success_rate']}")
        report.append(f"  â€¢ Hata SayÄ±sÄ±: {metrics['errors']}")
        
        report.append(f"\nâ±ï¸  PERFORMANS:")
        report.append(f"  â€¢ Ortalama YanÄ±t SÃ¼resi: {metrics['avg_response_time']}s")
        report.append(f"  â€¢ Medyan YanÄ±t SÃ¼resi: {metrics['median_response_time']}s")
        report.append(f"  â€¢ Maksimum YanÄ±t SÃ¼resi: {metrics['max_response_time']}s")
        
        report.append(f"\nğŸ“‚ KATEGORÄ° BAZLI BAÅARI ORANLARI:")
        for cat, data in sorted(metrics['category_scores'].items(), 
                               key=lambda x: x[1]['success_rate'], reverse=True):
            report.append(f"  â€¢ {cat:20s}: {data['passed']:2d}/{data['total']:2d} (%{data['success_rate']:5.1f})")
        
        report.append(f"\nğŸ¯ ZORLUK SEVÄ°YESÄ°NE GÃ–RE:")
        for diff in ['easy', 'medium', 'hard']:
            if diff in metrics['difficulty_scores']:
                data = metrics['difficulty_scores'][diff]
                report.append(f"  â€¢ {diff.capitalize():10s}: {data['passed']:2d}/{data['total']:2d} (%{data['success_rate']:5.1f})")
        
        # BaÅŸarÄ±sÄ±z testleri listele
        failed_tests = [r for r in self.results 
                       if not (r.contains_keywords and r.has_context and not r.error)]
        
        if failed_tests:
            report.append(f"\nâŒ BAÅARISIZ TESTLER ({len(failed_tests)} adet):")
            for i, test in enumerate(failed_tests[:10], 1):  # Ä°lk 10'u gÃ¶ster
                report.append(f"\n  {i}. [{test.category}] {test.question}")
                if not test.contains_keywords:
                    report.append(f"     â†’ Beklenen kelimeler bulunamadÄ±")
                if not test.has_context:
                    report.append(f"     â†’ Context bulunamadÄ±")
                if test.error:
                    report.append(f"     â†’ Hata: {test.error[:100]}")
            
            if len(failed_tests) > 10:
                report.append(f"\n  ... ve {len(failed_tests)-10} test daha")
        
        # Ã–neriler
        report.append(f"\nğŸ’¡ Ã–NERÄ°LER:")
        if metrics['overall_success_rate'] < 70:
            report.append(f"  âš ï¸  BaÅŸarÄ± oranÄ± dÃ¼ÅŸÃ¼k! RAG pipeline'Ä±nÄ±zÄ± gÃ¶zden geÃ§irin:")
            report.append(f"     - Embedding model kalitesi")
            report.append(f"     - Chunk stratejisi")
            report.append(f"     - Retrieval parametreleri (k, score threshold)")
        
        if metrics['avg_response_time'] > 3:
            report.append(f"  âš ï¸  YanÄ±t sÃ¼releri yÃ¼ksek! Optimizasyon Ã¶nerileri:")
            report.append(f"     - Batch processing")
            report.append(f"     - Cache mekanizmasÄ±")
            report.append(f"     - Model quantization")
        
        if metrics['errors'] > 0:
            report.append(f"  âš ï¸  Hata tespit edildi! Log dosyalarÄ±nÄ± inceleyin")
        
        report.append(f"\n{'='*60}")
        
        return "\n".join(report)
    
    def export_failed_for_annotation(self):
        """BaÅŸarÄ±sÄ±z testleri manuel deÄŸerlendirme iÃ§in export eder"""
        failed = [r for r in self.results 
                 if not (r.contains_keywords and r.has_context and not r.error)]
        
        if not failed:
            print("BaÅŸarÄ±sÄ±z test yok!")
            return
        
        annotation_file = os.path.join(self.output_dir, "failed_tests_for_review.json")
        
        annotation_data = []
        for r in failed:
            annotation_data.append({
                "question": r.question,
                "category": r.category,
                "answer": r.answer,
                "contexts": r.contexts,
                "review_notes": "",  # Manuel not alanÄ±
                "is_correct": None,  # True/False/None
                "suggested_improvement": ""
            })
        
        with open(annotation_file, 'w', encoding='utf-8') as f:
            json.dump(annotation_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ BaÅŸarÄ±sÄ±z {len(failed)} test manuel inceleme iÃ§in kaydedildi:")
        print(f"   {annotation_file}")


def main():
    """Ana Ã§alÄ±ÅŸtÄ±rma fonksiyonu"""
    import argparse
    
    parser = argparse.ArgumentParser(description='GTÃœ QA Bot Evaluation Suite')
    parser.add_argument('--workers', type=int, default=5, 
                       help='Paralel Ã§alÄ±ÅŸacak thread sayÄ±sÄ± (default: 5)')
    parser.add_argument('--output-dir', type=str, default=None,
                       help='SonuÃ§ dosyalarÄ±nÄ±n kaydedileceÄŸi dizin')
    parser.add_argument('--export-failed', action='store_true',
                       help='BaÅŸarÄ±sÄ±z testleri manuel inceleme iÃ§in export et')
    
    args = parser.parse_args()
    
    # Test runner'Ä± baÅŸlat
    runner = TestRunner(output_dir=args.output_dir)
    
    # Testleri Ã§alÄ±ÅŸtÄ±r
    runner.run_tests(max_workers=args.workers)
    
    # SonuÃ§larÄ± kaydet
    runner.save_results()
    
    # BaÅŸarÄ±sÄ±z testleri export et
    if args.export_failed:
        runner.export_failed_for_annotation()


if __name__ == "__main__":
    main()